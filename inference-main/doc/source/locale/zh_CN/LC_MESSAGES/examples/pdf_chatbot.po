# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-01 10:48+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../source/examples/pdf_chatbot.rst:5
msgid "Example: PDF Chatbot📚"
msgstr "示例：PDF 聊天机器人📚"

#: ../../source/examples/pdf_chatbot.rst:7
msgid "**Description**:"
msgstr "**描述**："

#: ../../source/examples/pdf_chatbot.rst:9
msgid ""
"This example showcases how to build a PDF chatbot with local LLM and "
"Embedding models"
msgstr ""
"这个例子展示了如何使用本地 LLM 和 embedding 模型构建PDF聊天机器人。"

#: ../../source/examples/pdf_chatbot.rst:11
msgid "**Used Technology**:"
msgstr "**涉及技术**："

#: ../../source/examples/pdf_chatbot.rst:13
msgid ""
"@ `Xinference <https://github.com/xorbitsai/inference>`_ as a LLM model "
"hosting service"
msgstr "@ `Xinference <https://github.com/xorbitsai/inference>`_ 作为LLM模型托管服务"

#: ../../source/examples/pdf_chatbot.rst:15
msgid ""
"@ `LlamaIndex <https://github.com/run-llama/llama_index>`_ for "
"orchestrating the entire RAG pipeline"
msgstr "@ `LlamaIndex <https://github.com/run-llama/llama_index>`_ 用于编排整个RAG管道"

#: ../../source/examples/pdf_chatbot.rst:17
msgid "@ `Streamlit <https://streamlit.io/>`_ for interactive UI"
msgstr "@ `Streamlit <https://streamlit.io/>`_ 用于交互式用户界面"

#: ../../source/examples/pdf_chatbot.rst:19
msgid "**Detailed Explanation on the Demo Functionality** :"
msgstr "**关于演示功能的详细说明**："

#: ../../source/examples/pdf_chatbot.rst:21
msgid ""
"Crafted a Dockerfile to simplify the process and ensure easy "
"reproducibility."
msgstr "制作了一个Dockerfile，通过 docker 简化了部署流程并确保易于复现。"

#: ../../source/examples/pdf_chatbot.rst:23
msgid "Set up models with Xinference and expose two ports for accessing them."
msgstr "使用 Xinference 拉起 LLM 和 embedding 模型，并暴露两个端口以访问它们。"

#: ../../source/examples/pdf_chatbot.rst:25
msgid ""
"Leverage Streamlit for seamless file uploads and interactive "
"communication with the chat engine."
msgstr "利用 Streamlit 实现无缝文件上传和与聊天引擎的交互通信。"

#: ../../source/examples/pdf_chatbot.rst:27
msgid "5x faster doc embedding than OpenAI's API."
msgstr "文档 embedding 速度比 OpenAI 的 API快5倍。"

#: ../../source/examples/pdf_chatbot.rst:29
msgid ""
"Leveraging the power of GGML to offload models to the GPU, ensuring swift"
" acceleration. Less long waits for returns."
msgstr "利用 GGML 的强大功能将模型置于GPU上运行，确保加速、减少等待返回的时间。"

#: ../../source/examples/pdf_chatbot.rst:31
msgid "**Source Code** :"
msgstr "**源代码**："

#: ../../source/examples/pdf_chatbot.rst:32
msgid ""
"`PDF Chatbot <https://github.com/onesuper/PDF-Chatbot-Local-LLM-"
"Embeddings>`_"
msgstr ""

